"use client";

import { useEffect, useRef, useState } from "react";
import { Icon } from "@iconify/react";
import { eventBus } from "@/lib/eventBus";

type StatusLabel = "Clique para falar" | "Conectando" | "Escutando";

interface ServeAIRealtimeVoiceProps {
  tableNumber?: string;
}

export default function ServeAIRealtimeVoice({
  tableNumber = "12",
}: ServeAIRealtimeVoiceProps) {
  const pc = useRef<RTCPeerConnection | null>(null);
  const dc = useRef<RTCDataChannel | null>(null);
  const mic = useRef<MediaStream | null>(null);

  const [status, setStatus] = useState<StatusLabel>("Clique para falar");
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const [menu, setMenu] = useState<any[]>([]);

  // ============================================================
  // 1) CARREGAR CARDÃPIO UMA VEZ
  // ============================================================
  useEffect(() => {
    fetch("http://localhost:1337/menu")
      .then((r) => r.json())
      .then((data) => {
        setMenu(data);
        console.log("ðŸ” MENU CARREGADO:", data);
      })
      .catch((err) => console.error("Erro menu:", err));
  }, []);

  // ============================================================
  // 2) SYSTEM PROMPT FINAL
  // ============================================================
  function buildSystemPrompt() {
    return `
VocÃª Ã© o ATENDENTE VIRTUAL do restaurante.
Fale SEMPRE em portuguÃªs do Brasil, de forma educada, curta e objetiva.

=====================================================================
REGRAS ABSOLUTAS (NÃƒO QUEBRAR)
=====================================================================
1. NÃ£o invente itens, preÃ§os, promoÃ§Ãµes ou quantidades.
2. NÃƒO execute tools sem intenÃ§Ã£o CLARA do cliente.
3. NÃƒO execute tools baseadas em frases vagas como:
   - "beleza"
   - "ok"
   - "tranquilo"
   - "qualquer coisa eu chamo"
   - "tudo bem"
   - "pode ser"
   - "tÃ¡ bom"
   Essas frases NÃƒO indicam intenÃ§Ã£o â†’ responda cordialmente sem executar tool.
4. Se o cliente cumprimentar ("boa tarde", "oi", etc.), responda normalmente.
5. SÃ³ acione ferramentas quando:
   - houver um item do cardÃ¡pio mencionado
   - houver um verbo de aÃ§Ã£o claro ("quero", "adicionar", "coloca", "remove")

=====================================================================
DETECÃ‡ÃƒO DE INTENÃ‡Ã•ES
=====================================================================

1) list_menu_items â†’ Use quando cliente pedir:
   - â€œme mostra o cardÃ¡pioâ€
   - â€œquais sÃ£o as pizzas?â€
   - â€œquais sÃ£o as bebidas?â€
   - â€œmostrar cardÃ¡pio geralâ€
   â€¢ Se pedir cardÃ¡pio geral â†’ query ""
   â€¢ Se citar categoria â†’ query com a categoria

2) add_to_order â†’ Use SOMENTE quando:
   - houver item do cardÃ¡pio citado PELO NOME
   - houver verbo claro: â€œcolocaâ€, â€œadicionaâ€, â€œqueroâ€, â€œpode trazerâ€

3) remove_from_order â†’ Use SOMENTE quando:
   - o cliente citar item + verbo â€œremoverâ€, â€œtirarâ€, â€œsemâ€

4) get_order_summary â†’ Use quando perguntar:
   - â€œqual o total?â€
   - â€œquanto deu?â€
   - â€œme diz o totalâ€

=====================================================================
PROTOCOLO OBRIGATÃ“RIO
=====================================================================
1. Antes de tool â†’ Fale UMA frase curta:
   - "Claro, vou adicionar."
   - "Perfeito, vou remover."
   - "Um instante, vou verificar."
   - "Vou te mostrar."

2. ApÃ³s tool:
   - Use exatamente o texto retornado pela ferramenta.
   - Nunca altere valores.
   - Termine com: â€œDeseja mais alguma coisa?â€

=====================================================================
CARDÃPIO OFICIAL (NÃƒO INVENTAR NADA)
=====================================================================
${JSON.stringify(menu, null, 2)}
`;
  }

  // ============================================================
  // 3) INICIAR VOZ / WEBRTC
  // ============================================================
  async function startVoice() {
    if (status !== "Clique para falar") {
      stopVoice();
      return;
    }

    setStatus("Conectando");

    // 3.1 Buscar client_secret
    const session = await fetch("http://localhost:1337/session").then((r) =>
      r.json()
    );

    // 3.2 Criar conexÃµes
    pc.current = new RTCPeerConnection();
    dc.current = pc.current.createDataChannel("oai-events");

    // 3.3 Canal aberto
    dc.current.onopen = () => {
      setStatus("Escutando");
      console.log("ðŸŸ¢ Canal WebRTC aberto!");

      send({
        type: "session.update",
        session: {
          instructions: buildSystemPrompt(),
        },
      });

      send({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
          instructions: "Atenda o cliente normalmente.",
        },
      });
    };

    dc.current.onmessage = handleEvent;

    // 3.4 Ã¡udio retornado pela IA
    const audio = new Audio();
    audio.autoplay = true;
    pc.current.ontrack = (event) => {
      audio.srcObject = event.streams[0];
    };

    // 3.5 microfone
    mic.current = await navigator.mediaDevices.getUserMedia({ audio: true });
    mic.current
      .getTracks()
      .forEach((t) => pc.current!.addTrack(t, mic.current!));

    // 3.6 handshake WebRTC
    const offer = await pc.current.createOffer();
    await pc.current.setLocalDescription(offer);

    const r = await fetch(
      "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview",
      {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${session.client_secret.value}`,
          "Content-Type": "application/sdp",
        },
      }
    );

    const answerSdp = await r.text();

    await pc.current.setRemoteDescription({
      type: "answer",
      sdp: answerSdp,
    });
  }

  function stopVoice() {
    setStatus("Clique para falar");
    try {
      dc.current?.close();
      pc.current?.close();
      mic.current?.getTracks().forEach((t) => t.stop());
    } catch {}

    eventBus.emit("ia:stop", null);
  }

  // ============================================================
  // 4) Envio
  // ============================================================
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  function send(obj: any) {
    if (dc.current?.readyState === "open") {
      dc.current.send(JSON.stringify(obj));
    }
  }

  // ============================================================
  // 5) EVENTOS DA IA (FINAL)
  // ============================================================
  async function handleEvent(msg: MessageEvent) {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    let ev: any;
    try {
      ev = JSON.parse(msg.data);
    } catch {
      return;
    }

    console.log("ðŸ“© EVENTO IA:", ev);

    // SALVAR TEXTO FINAL NO BACKEND
    if (ev.type === "response.text.done" && ev.text) {
      fetch("http://localhost:1337/transcript", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ tableNumber, text: ev.text }),
      }).catch(() => {});
    }

    // CHAMADA DE TOOL
    if (ev.type === "response.function_call_arguments.done") {
      const toolName = ev.name;
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      let args: any = {};

      try {
        args = ev.arguments ? JSON.parse(ev.arguments) : {};
      } catch {}

      args.tableNumber = tableNumber;

      console.log("ðŸ›  Chamando tool backend:", toolName, args);

      const toolResponse = await fetch("http://localhost:1337/tool-call", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ name: toolName, args }),
      }).then((r) => r.json());

      // ðŸ”¥ðŸ”¥ EMITE EVENTO DE ATUALIZAÃ‡ÃƒO AO FRONT
      if (toolName === "add_to_order") {
        eventBus.emit("pedido:add", {
          id: args.menuItemId,
          quantity: args.quantity ?? 1,
        });
      }

      if (toolName === "remove_from_order") {
        eventBus.emit("pedido:remove", {
          id: args.menuItemId,
        });
      }

      const toolText =
        toolResponse?.result?.message ||
        toolResponse?.message ||
        JSON.stringify(toolResponse?.result || toolResponse);

      // 1) Entregar resultado pro modelo
      send({
        type: "conversation.item.create",
        item: {
          type: "function_call_output",
          call_id: ev.call_id,
          output: toolText,
        },
      });

      // 2) Pedir continuaÃ§Ã£o em Ã¡udio
      send({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
          instructions:
            "Use o resultado enviado e responda ao cliente educadamente.",
        },
      });
    }
  }

  return (
    <div className="flex flex-col items-center gap-4 p-4">
      <button
        onClick={status === "Clique para falar" ? startVoice : stopVoice}
        className={`flex items-center gap-2 bg-gradient-to-r 
          ${
            status === "Clique para falar"
              ? "from-[#8b5cf6] to-[#3b82f6]"
              : "from-red-500 to-red-700"
          }
          text-white px-4 py-2 rounded-xl text-sm shadow hover:opacity-90 transition`}
      >
        {status === "Clique para falar" ? (
          <>
            <Icon icon="fluent:mic-24-filled" className="w-4 h-4" />
            Falar
          </>
        ) : (
          <>
            <Icon icon="fluent:mic-off-24-filled" className="w-4 h-4" />
            Parar
          </>
        )}
      </button>

      <div className="text-sm text-gray-600">
        Status: <b>{status}</b> â€¢ Mesa {tableNumber}
      </div>
    </div>
  );
}
